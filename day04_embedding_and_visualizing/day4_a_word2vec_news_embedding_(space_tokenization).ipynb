{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장을 띄어쓰기 만으로 토크나이징을 할 수도 있습니다. 데이터의 숫자가 정말로 풍부하고, 모델이 수많은 어절을 그대로 학습할 수 있을만큼의 하드웨어라면, 어절을 그대로 Word2Vec 학습하여도 그 결과는 충분히 쓸만합니다만, 그 목적이 다를 수 있습니다. 아래에서 그 예시를 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soynlp=0.0.493\n",
      "added lovit_textmining_dataset\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from navernews_10days import get_news_paths\n",
    "\n",
    "path = get_news_paths(date='2016-10-20', tokenize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soynlp.utils.DoublespaceLineCorpus 를 이용하여 list of str 이 yield 되는 input data 를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['19']\n",
      "['1990']\n",
      "['52', '1', '22']\n",
      "['오패산터널', '총격전', '용의자', '검거', '서울', '연합뉴스', '경찰', '관계자들이', '19일', '오후']\n",
      "['서울', '연합뉴스', '김은경', '기자', '사제', '총기로', '경찰을', '살해한', '범인', '성모']\n",
      "['경찰에', '따르면', '성씨는', '19일', '오후', '강북경찰서', '인근', '부동산', '업소', '밖에서']\n"
     ]
    }
   ],
   "source": [
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "    \n",
    "class Word2VecCorpus:\n",
    "    def __init__(self, fname):\n",
    "        self.corpus = DoublespaceLineCorpus(fname, iter_sent=True)\n",
    "    def __iter__(self):\n",
    "        for sent in self.corpus:\n",
    "            yield sent.split()\n",
    "                \n",
    "word2vec_corpus = Word2VecCorpus(path)\n",
    "for num_sent, sent in enumerate(word2vec_corpus):\n",
    "    if num_sent > 5:\n",
    "        break\n",
    "    print(sent[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_model = Word2Vec(word2vec_corpus, min_count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = '김무성 박근혜 문재인 국방부 정부 국정원 대통령 축구 외교 정책 군대 미국 일본 중국 아이오아이'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어절만 이용하여 학습했음에도 불구하고, 김무성의 유사어로 정치인들이 등장함을 볼 수 있습니다. 이는 뉴스 코퍼스에서는 정치인의 이름만 적고 띄어쓰기를 하는 경우도 충분하기 때문입니다. \n",
    "\n",
    "하지만 '김무성 - 대표도'와 같은 유사 어절이 등장한 것은, 뉴스에서 '김무성'으로만 적는 경우와 '김무성 대표도'로 적는 경우가 혼재되어 있어서, '대표도'의 문맥이 '김무성'의 문맥과 유사하였기 때문입니다. \n",
    "\n",
    "비슷한 의미로, 박근혜 - 박 (6251)의 경우에는 '박근혜 대통령', '박 대통령'이 번갈아가며 이용되었기 때문입니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나, 국정원의 경우에는 총 42번 나왔으며, min_count=30으로 하였기 때문에 18000여개의 단어 중에서는 infrequent 한 편에 속합니다. 그리고 이 때의 유사 어절들은 문맥상 잘 어울리지 않는 어절들입니다. \n",
    "\n",
    "    Vocab(count:42, index:12945, sample_int:4294967296)\n",
    "    국정원 - 단국대 (33) (0.774)\n",
    "    국정원 - 대우학원 (34) (0.726)\n",
    "    국정원 - 김형수 (92) (0.722)\n",
    "    국정원 - 인터뷰가 (36) (0.717)\n",
    "    국정원 - 입 (59) (0.711)\n",
    "    국정원 - 정동구 (31) (0.709)\n",
    "    국정원 - 정유라씨가 (41) (0.705)\n",
    "    국정원 - 취재진이 (33) (0.703)\n",
    "    국정원 - 크리스 (33) (0.696)\n",
    "    국정원 - 이사장을 (81) (0.696)\n",
    "    \n",
    "Word2Vec에서는 infrequent 한 단어(어절)들의 유사 단어(어절)들은 infrequent 한 경향이 있습니다. 빈도수가 충분하지 않을 경우에는 학습이 잘 되지 않는 것이라고 해석할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어절을 그대로 학습할 경우에는, 아래와 같이 대통령의 유사어절로 '대통령 + 조사'의 어절들이 자주 등장합니다. \n",
    "    \n",
    "    Seed word = 대통령\n",
    "    Vocab(count:3411, index:89, sample_int:4294967296)\n",
    "    대통령 - 대통령의 (3074) (0.809)\n",
    "    대통령 - 대통령을 (287) (0.784)\n",
    "    대통령 - 대통령과 (437) (0.784)\n",
    "    대통령 - 대통령에 (255) (0.723)\n",
    "    대통령 - 대통령은 (2852) (0.716)\n",
    "    대통령 - 대통령에게 (203) (0.708)\n",
    "    대통령 - 대통령도 (125) (0.704)\n",
    "    대통령 - 대통령이다 (54) (0.698)\n",
    "    대통령 - 대통령이 (5054) (0.698)\n",
    "    대통령 - 정부에서 (76) (0.687)\n",
    "    \n",
    "우리가 원하는 것이 Language model을 학습하는 것이라면, 이 결과는 유용합니다. 하지만, 우리가 문맥적으로 유사한 단어들을 찾기 위하여 Word2Vec을 학습하는 것이 목적이었다면, 어절을 그대로 학습하는 것보다 토크나이징을 한 뒤, 이를 이용하여 학습해야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Query = 김무성\n",
      "Vocab(count:40, index:13718, sample_int:4294967296)\n",
      "김무성 - 김종인 (87, 0.892)\n",
      "김무성 - 대표와 (232, 0.879)\n",
      "김무성 - 이재오 (32, 0.867)\n",
      "김무성 - 사무총장 (104, 0.856)\n",
      "김무성 - 안철수 (193, 0.856)\n",
      "김무성 - 오세훈 (34, 0.841)\n",
      "김무성 - 정의화 (33, 0.829)\n",
      "김무성 - 서울시장 (37, 0.829)\n",
      "김무성 - 김문수 (69, 0.823)\n",
      "김무성 - 김부겸 (39, 0.818)\n",
      "\n",
      "\n",
      "Query = 박근혜\n",
      "Vocab(count:1412, index:261, sample_int:4294967296)\n",
      "박근혜 - 올랑드 (53, 0.786)\n",
      "박근혜 - 박 (2276, 0.785)\n",
      "박근혜 - 두테르테 (334, 0.757)\n",
      "박근혜 - 노 (190, 0.742)\n",
      "박근혜 - 푸틴 (124, 0.732)\n",
      "박근혜 - 오바마 (229, 0.713)\n",
      "박근혜 - 정권 (183, 0.677)\n",
      "박근혜 - 노무현 (266, 0.665)\n",
      "박근혜 - 대통령이 (1454, 0.648)\n",
      "박근혜 - 블라디미르 (73, 0.646)\n",
      "\n",
      "\n",
      "Query = 문재인\n",
      "Vocab(count:933, index:411, sample_int:4294967296)\n",
      "문재인 - 안철수 (193, 0.878)\n",
      "문재인 - 문 (742, 0.871)\n",
      "문재인 - 반기문 (136, 0.842)\n",
      "문재인 - 송민순 (814, 0.793)\n",
      "문재인 - 당내 (73, 0.788)\n",
      "문재인 - 김종인 (87, 0.784)\n",
      "문재인 - 송 (339, 0.781)\n",
      "문재인 - 대표의 (613, 0.780)\n",
      "문재인 - 탈당 (189, 0.779)\n",
      "문재인 - 색깔론 (68, 0.779)\n",
      "\n",
      "\n",
      "Query = 국방부\n",
      "Vocab(count:327, index:1515, sample_int:4294967296)\n",
      "국방부 - 한민구 (143, 0.906)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "/home/lovit/anaconda3/envs/pytorch/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "국방부 - 카터 (207, 0.901)\n",
      "국방부 - 국방장관이 (83, 0.860)\n",
      "국방부 - 케리 (401, 0.859)\n",
      "국방부 - 애슈턴 (130, 0.859)\n",
      "국방부 - 윤병세 (297, 0.858)\n",
      "국방부 - 산업통상자원부 (114, 0.846)\n",
      "국방부 - 외교부 (418, 0.839)\n",
      "국방부 - 참석하는 (94, 0.833)\n",
      "국방부 - 국무장관과 (40, 0.832)\n",
      "\n",
      "\n",
      "Query = 정부\n",
      "Vocab(count:1005, index:380, sample_int:4294967296)\n",
      "정부 - 정부의 (677, 0.888)\n",
      "정부 - 정부와 (203, 0.822)\n",
      "정부 - 예산 (305, 0.778)\n",
      "정부 - 현 (689, 0.762)\n",
      "정부 - 정부는 (726, 0.760)\n",
      "정부 - 정부에서 (98, 0.757)\n",
      "정부 - 보수 (88, 0.756)\n",
      "정부 - 누리과정 (45, 0.744)\n",
      "정부 - 내년도 (114, 0.732)\n",
      "정부 - 구조조정 (166, 0.729)\n",
      "\n",
      "\n",
      "Query = 국정원\n",
      "Vocab(count:284, index:1794, sample_int:4294967296)\n",
      "국정원 - 국감에서 (136, 0.812)\n",
      "국정원 - 이병호 (366, 0.790)\n",
      "국정원 - 정보위 (292, 0.785)\n",
      "국정원 - 통화에서 (130, 0.775)\n",
      "국정원 - 국가정보원 (41, 0.773)\n",
      "국정원 - 연합뉴스와의 (37, 0.761)\n",
      "국정원 - 김도읍 (92, 0.758)\n",
      "국정원 - 국정원장의 (162, 0.747)\n",
      "국정원 - 정보위원회 (121, 0.744)\n",
      "국정원 - 정세균 (44, 0.742)\n",
      "\n",
      "\n",
      "Query = 대통령\n",
      "Vocab(count:1187, index:309, sample_int:4294967296)\n",
      "대통령 - 대통령과 (197, 0.857)\n",
      "대통령 - 대통령의 (856, 0.850)\n",
      "대통령 - 대통령도 (53, 0.829)\n",
      "대통령 - 이명박 (70, 0.824)\n",
      "대통령 - 박정희 (48, 0.822)\n",
      "대통령 - 김대중 (74, 0.809)\n",
      "대통령 - 노무현 (266, 0.798)\n",
      "대통령 - 대통령이 (1454, 0.795)\n",
      "대통령 - 대통령을 (180, 0.787)\n",
      "대통령 - 경선 (41, 0.784)\n",
      "\n",
      "\n",
      "Query = 축구\n",
      "Vocab(count:36, index:15179, sample_int:4294967296)\n",
      "축구 - 연주 (43, 0.736)\n",
      "축구 - 민족 (36, 0.733)\n",
      "축구 - 1세대 (39, 0.730)\n",
      "축구 - 오케스트라 (54, 0.709)\n",
      "축구 - 생체 (48, 0.701)\n",
      "축구 - 3위에 (30, 0.700)\n",
      "축구 - 댄 (38, 0.699)\n",
      "축구 - 두산 (49, 0.699)\n",
      "축구 - 5개의 (35, 0.697)\n",
      "축구 - 함정 (37, 0.694)\n",
      "\n",
      "\n",
      "Query = 외교\n",
      "Vocab(count:757, index:542, sample_int:4294967296)\n",
      "외교 - 국방 (297, 0.939)\n",
      "외교 - 차관급 (50, 0.903)\n",
      "외교 - 외교와 (32, 0.901)\n",
      "외교 - 고위급 (165, 0.893)\n",
      "외교 - 한미 (864, 0.887)\n",
      "외교 - 양국은 (219, 0.866)\n",
      "외교 - 국방장관 (310, 0.858)\n",
      "외교 - 양국이 (120, 0.828)\n",
      "외교 - 양국 (487, 0.828)\n",
      "외교 - 미군의 (31, 0.816)\n",
      "\n",
      "\n",
      "Query = 정책\n",
      "Vocab(count:441, index:1063, sample_int:4294967296)\n",
      "정책 - 정책의 (76, 0.870)\n",
      "정책 - 안보 (183, 0.839)\n",
      "정책 - 규제 (331, 0.828)\n",
      "정책 - 정부의 (677, 0.815)\n",
      "정책 - 차원의 (217, 0.812)\n",
      "정책 - 논의가 (129, 0.812)\n",
      "정책 - 정책과 (62, 0.811)\n",
      "정책 - 제도 (218, 0.800)\n",
      "정책 - 정책을 (280, 0.799)\n",
      "정책 - 협력 (311, 0.791)\n",
      "\n",
      "\n",
      "Query = 미국\n",
      "Vocab(count:4057, index:75, sample_int:4294967296)\n",
      "미국 - 미국과 (226, 0.735)\n",
      "미국 - 영국 (611, 0.734)\n",
      "미국 - 일본 (1615, 0.734)\n",
      "미국 - 러시아 (395, 0.723)\n",
      "미국 - 인도 (198, 0.721)\n",
      "미국 - 미국의 (951, 0.714)\n",
      "미국 - 해군 (170, 0.712)\n",
      "미국 - 한국과 (319, 0.708)\n",
      "미국 - 시카고 (67, 0.706)\n",
      "미국 - 미 (1264, 0.702)\n",
      "\n",
      "\n",
      "Query = 일본\n",
      "Vocab(count:1615, index:227, sample_int:4294967296)\n",
      "일본 - 호주 (236, 0.841)\n",
      "일본 - 중국 (2523, 0.840)\n",
      "일본 - 영국 (611, 0.826)\n",
      "일본 - 홍콩 (207, 0.806)\n",
      "일본 - 한국 (1681, 0.797)\n",
      "일본 - 대만 (186, 0.795)\n",
      "일본 - 태국 (127, 0.795)\n",
      "일본 - 싱가포르 (105, 0.787)\n",
      "일본 - 인도 (198, 0.783)\n",
      "일본 - 터키 (65, 0.769)\n",
      "\n",
      "\n",
      "Query = 중국\n",
      "Vocab(count:2523, index:132, sample_int:4294967296)\n",
      "중국 - 일본 (1615, 0.840)\n",
      "중국 - 중국의 (365, 0.768)\n",
      "중국 - 인도 (198, 0.765)\n",
      "중국 - 인도네시아 (194, 0.758)\n",
      "중국 - 한국 (1681, 0.740)\n",
      "중국 - 유럽 (540, 0.737)\n",
      "중국 - 터키 (65, 0.729)\n",
      "중국 - 일본의 (273, 0.725)\n",
      "중국 - 일본과 (69, 0.721)\n",
      "중국 - 호주 (236, 0.717)\n",
      "\n",
      "\n",
      "Query = 아이오아이\n",
      "Vocab(count:123, index:4400, sample_int:4294967296)\n",
      "아이오아이 - 몬스타엑스 (69, 0.929)\n",
      "아이오아이 - 방탄소년단 (200, 0.919)\n",
      "아이오아이 - 샤이니 (173, 0.891)\n",
      "아이오아이 - 몬스타 (56, 0.890)\n",
      "아이오아이 - 신용재 (33, 0.888)\n",
      "아이오아이 - 갓세븐 (32, 0.887)\n",
      "아이오아이 - 코드 (41, 0.887)\n",
      "아이오아이 - 엑스 (44, 0.886)\n",
      "아이오아이 - 에이핑크 (159, 0.886)\n",
      "아이오아이 - 샤이니가 (40, 0.882)\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "\n",
    "    if not (query in word2vec_model.wv.vocab):\n",
    "        continue\n",
    "\n",
    "    print('\\n\\nQuery = {}\\n{}'.format(query, word2vec_model.wv.vocab[query]))\n",
    "\n",
    "    for sim_word, sim in word2vec_model.most_similar(query):\n",
    "        sim_count = word2vec_model.wv.vocab[sim_word].count\n",
    "        print('%s - %s (%d, %.3f)' % (query, sim_word, sim_count, sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

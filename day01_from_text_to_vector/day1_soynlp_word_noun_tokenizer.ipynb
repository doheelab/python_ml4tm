{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "앞서 살펴본 단어 추출 방법 및 명사 추출 방법은 soynlp 에 모아서 구현해뒀습니다. 이를 이용하여 2016-10-20 뉴스에서 명사를 추출하는 실습과 단어 점수를 계산하는 코드를 실습해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.493\n"
     ]
    }
   ],
   "source": [
    "import soynlp\n",
    "print(soynlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "from lovit_textmining_dataset.navernews_10days import get_news_paths\n",
    "\n",
    "corpus_path = get_news_paths(date='2016-10-20')\n",
    "corpus = DoublespaceLineCorpus(corpus_path, iter_sent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordExtractor (Cohesion score, Branching Entropy, Accessor Variety)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordExtractor는 Cohesion score, Branching Entropy, Accessor Variety 등을 한번에 계산할 수 있도록 만들어둔 클래스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.741 Gbse memory 0.794 Gb\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor(\n",
    "    max_left_length=10,\n",
    "    max_right_length=6,\n",
    "    min_frequency=5\n",
    ")\n",
    "word_extractor.train(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordExtractor.word_scores()를 하면, 모든 L, R의 subwords에 대하여 앞서 함께 연습한 Cohesion score, Branching Entropy, Accessor Variety, frequency 등을 모두 계산하여 출력하도록 해두었습니다. 여기서 계산하는 Branching Entropy는 어절 간의 글자들도 고려한 수치입니다.\n",
    "\n",
    "return type은 {word:namedtuple} 형식입니다. Python의 namedtuple 형식이기 때문에 .을 이용하여 해당 값을 손쉽게 가져올 수 있습니다. \n",
    "\n",
    "leftside_frequency는 해당 단어가 L에 등장한 횟수이며, rightside_frequency는 해당 단어가 R에 등장한 횟수입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 360721\n",
      "all accessor variety was computed # words = 360721\n"
     ]
    }
   ],
   "source": [
    "scores = word_extractor.word_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scores(cohesion_forward=0.487322733132789, cohesion_backward=0.22771099423991986, left_branching_entropy=2.877143706774324, right_branching_entropy=3.128831672462708, left_accessor_variety=144, right_accessor_variety=215, leftside_frequency=11340, rightside_frequency=7274)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['뉴스']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.487322733132789"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['뉴스'].cohesion_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원 논문에서는 띄어쓰기가 없다고 가정합니다. 하지만 한국어에는 일부 띄어쓰기가 있습니다. 예를 들어 아래 문장에서 `에트와` 사이에는 띄어쓰기가 있기 때문에 `에트와`는 단어가 될 수 없습니다. soynlp 에는 이러한 정보를 이용하여 한국어에 적합한 branching entropy 와 accessor variety 를 계산합니다.\n",
    "\n",
    "```\n",
    "음악중심에 트와이스가 나왔습니다\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "트와이 (2.994, -0.000)\n",
      "트와이스 (2.994, 2.046)\n"
     ]
    }
   ],
   "source": [
    "for word in ['트와이', '트와이스']:\n",
    "    lbe = scores[word].left_branching_entropy\n",
    "    rbe = scores[word].right_branching_entropy\n",
    "    print(word, '(%.3f, %.3f)' % (lbe, rbe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohesion 만 계산하고 싶다면 아래의 함수를 이용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cohesion probabilities was computed. # words = 223348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.487322733132789, 0.22771099423991986)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {word:(cohesion_l, cohesion_r)}\n",
    "cohesion_scores = word_extractor.all_cohesion_scores()\n",
    "cohesion_scores['뉴스']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 외에 braching entropy 나 accessor variety 만 계산하고 싶다면 아래의 함수를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all branching entropies was computed # words = 360721\n",
      "all accessor variety was computed # words = 360721\n"
     ]
    }
   ],
   "source": [
    "branching_entropy = word_extractor.all_branching_entropy()\n",
    "accessor_variety = word_extractor.all_accessor_variety()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun extraction\n",
    "\n",
    "명사 추출기 버전이 3 개가 있는데, 모델을 계속 개선하며 이전 모델을 남겨둔 것입니다. v2 는 성능이 가장 많이 개선된 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=3929, neg=2321, common=107\n",
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 403896 from 223357 sents. mem=0.932 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=4434442, mem=1.571 Gb\n",
      "[Noun Extractor] batch prediction was completed for 119705 words\n",
      "[Noun Extractor] checked compounds. discovered 70639 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 32506 -> 32351\n",
      "[Noun Extractor] postprocessing ignore_features : 32351 -> 32167\n",
      "[Noun Extractor] postprocessing ignore_NJ : 32167 -> 31921\n",
      "[Noun Extractor] 31921 nouns (70639 compounds) with min frequency=5\n",
      "[Noun Extractor] flushing was done. mem=1.778 Gb                    \n",
      "[Noun Extractor] 76.04 % eojeols are covered\n"
     ]
    }
   ],
   "source": [
    "from soynlp.noun import LRNounExtractor\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "from soynlp.noun import NewsNounExtractor\n",
    "\n",
    "# noun_extractor = LRNounExtractor()\n",
    "noun_extractor = LRNounExtractor_v2()\n",
    "nouns = noun_extractor.train_extract(corpus, min_noun_frequency=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정부: NounScore(frequency=3251, score=0.9893238434163701)\n",
      "정부의: \n",
      "알아: NounScore(frequency=104, score=0.32786885245901637)\n",
      "알아냈: \n",
      "트와이스: NounScore(frequency=654, score=0.992831541218638)\n",
      "아이디: NounScore(frequency=100, score=1.0)\n",
      "아이디어: NounScore(frequency=251, score=1.0)\n",
      "아이오아이: NounScore(frequency=250, score=1.0)\n"
     ]
    }
   ],
   "source": [
    "for word in ['정부', '정부의', '알아', '알아냈', '트와이스', '아이디', '아이디어', '아이오아이']:\n",
    "    print('{}: {}'.format(word, nouns.get(word, '')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "띄어쓰기가 잘 된 데이터에서 명사나 어간 부분만 잘라내기 위해서는 L-Tokenizer 도 충분합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['박근혜', '게이트', '에', '대한', '조사', '가', '시작', '되었습니다']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import LTokenizer,MaxScoreTokenizer, RegexTokenizer\n",
    "\n",
    "cohesion_scores = {word:score.cohesion_forward for word, score in scores.items()}\n",
    "ltokenizer = LTokenizer(scores=cohesion_scores)\n",
    "\n",
    "ltokenizer.tokenize('박근혜 게이트에 대한 조사가 시작되었습니다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('박근혜', ''), ('게이트', '에'), ('대한', ''), ('조사', '가'), ('시작', '되었습니다')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltokenizer.tokenize('박근혜 게이트에 대한 조사가 시작되었습니다', flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['박근혜', '게이트', '대한', '조사', '시작']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltokenizer.tokenize('박근혜 게이트에 대한 조사가 시작되었습니다', remove_r=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxScoreTokenizer 역시 단어 점수가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['박근혜', '게이트', '에', '대한', '조사', '가', '시작', '되었습니다']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxscoretokenizer = MaxScoreTokenizer(scores=cohesion_scores)\n",
    "maxscoretokenizer.tokenize('박근혜 게이트에 대한 조사가 시작되었습니다'.replace(' ',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('박근혜', 0, 3, 0.33444481802269577, 3),\n",
       "  ('게이트', 3, 6, 0.30753526965628375, 3),\n",
       "  ('에', 6, 7, 0.0, 1),\n",
       "  ('대한', 7, 9, 0.1611131928631136, 2),\n",
       "  ('조사', 9, 11, 0.164128519137783, 2),\n",
       "  ('가', 11, 12, 0.0, 1),\n",
       "  ('시작', 12, 14, 0.1257767904844923, 2),\n",
       "  ('되었습니다', 14, 19, 0.2762976357271788, 5)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxscoretokenizer.tokenize('박근혜 게이트에 대한 조사가 시작되었습니다'.replace(' ',''), flatten=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패턴을 이용하여 기본적인 띄어쓰기도 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이것', '123', 'abc', '유후']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regextokenizer = RegexTokenizer()\n",
    "regextokenizer.tokenize('이것123abc유후')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아니ㅋㅋㅠㅠ이럴수가흐규흐규'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import normalize\n",
    "\n",
    "normalize('아닠ㅋㅋㅋㅋㅋㅋㅋ큐ㅠㅠㅠㅠㅠㅠ이럴수가흐규흐규흐규흐규', num_repeat=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

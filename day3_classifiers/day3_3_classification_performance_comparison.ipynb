{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers 를 비교하기 위하여 10 개 영화의 평점 데이터를 이용합니다. 1 ~ 3 점은 negative, 9 ~ 10 은 positive class 이며, 4 ~ 8 점의 데이터는 무시하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.3\n",
      "(10000, 4808)\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import sklearn\n",
    "import warnings\n",
    "from navermovie_comments import load_sentiment_dataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(sklearn.__version__)\n",
    "\n",
    "texts, x, y, idx_to_vocab = load_sentiment_dataset(data_name='10k', tokenize='komoran')\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.unique 를 이용하면 실제 값들을 확인할 수 있습니다. negative 는 -1, positive 는 1 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree 의 depth 별로 classification 의 성능과 decision tree 가 이용하는 features 의 개수를 확인합니다.\n",
    "\n",
    "Depth 외의 다른 features 는 기본값으로 고정합니다.\n",
    "\n",
    "cross validation 을 이용하여 일반화 성능을 추정합니다. 10-fold cross validation 을 이용하였고, 이용하는 features 의 개수를 확인하기 위하여 데이터 모두를 이용하여 학습시켰습니다.\n",
    "\n",
    "scikit-learn = 0.20.0 부터 cross_val_score 는 sklearn.cross_validation.cross_val_score 에서 sklearn.mdoel_selection.cross_val_score 로 이동하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth = 10, cross-validation average = 0.7664, n useful featuers = 97\n",
      "depth = 20, cross-validation average = 0.7777, n useful featuers = 240\n",
      "depth = 30, cross-validation average = 0.7783, n useful featuers = 344\n",
      "depth = 50, cross-validation average = 0.7838, n useful featuers = 518\n",
      "depth = 100, cross-validation average = 0.7874, n useful featuers = 714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "n_cv = 10\n",
    "\n",
    "# for each depth\n",
    "for depth in [10, 20, 30, 50, 100]:\n",
    "    \n",
    "    # build decision tree\n",
    "    decision_tree = DecisionTreeClassifier(\n",
    "        max_features=None,\n",
    "        max_depth=depth\n",
    "    )\n",
    "    \n",
    "    # train cross-validation\n",
    "    scores = cross_val_score(\n",
    "        decision_tree, x, y, cv=n_cv)\n",
    "    average_score = sum(scores) / n_cv\n",
    "    \n",
    "    # re-train using all data\n",
    "    decision_tree.fit(x,y)\n",
    "    \n",
    "    # number of used features\n",
    "    useful_features = list(\n",
    "        filter(lambda x:x[1]>0,\n",
    "               enumerate(decision_tree.feature_importances_)\n",
    "              )\n",
    "    )\n",
    "    n_useful_features = len(useful_features)\n",
    "\n",
    "    print('depth = {}, cross-validation average = {:.4}, n useful featuers = {}'.format(depth, average_score, n_useful_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 regularization 을 적용하는 lasso regression 을 학습합니다. Lasso 도 decision tree 처럼 유용한 features 를 선택하는 특징이 있습니다. 이 둘의 성능을 비교합니다.\n",
    "\n",
    "Lasso regression 이 이용하는 features 의 개수는 regularization cost 를 통하여 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 lambda = 0.01, cross-validation = 0.8205, n useful features = 2502\n",
      "L1 lambda = 0.1, cross-validation = 0.8473, n useful features = 2170\n",
      "L1 lambda = 1.0, cross-validation = 0.858, n useful features = 1108\n",
      "L1 lambda = 10.0, cross-validation = 0.8194000000000001, n useful features = 181\n",
      "L1 lambda = 100.0, cross-validation = 0.7269999999999999, n useful features = 20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for each cost\n",
    "for cost in [100, 10, 1, 0.1, 0.01]:\n",
    "\n",
    "    # build lasso regression\n",
    "    logistic_regression = LogisticRegression(\n",
    "        penalty='l1', C=cost)\n",
    "\n",
    "    # train cross validation\n",
    "    scores = cross_val_score(\n",
    "        logistic_regression, x, y, cv=n_cv)\n",
    "    average_score = sum(scores) / n_cv\n",
    "\n",
    "    # re-train using all data\n",
    "    logistic_regression.fit(x,y)\n",
    "\n",
    "    # number of used features\n",
    "    useful_features = list(\n",
    "        filter(lambda x:abs(x[1])>0,\n",
    "               enumerate(logistic_regression.coef_[0])\n",
    "              )\n",
    "    )\n",
    "\n",
    "    n_useful_features = len(useful_features)\n",
    "\n",
    "    print('L1 lambda = {}, cross-validation = {}, n useful features = {}'.format(1/cost, average_score, n_useful_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso 대신 L2 regularization 을 적용한 logistic regression 도 함께 돌려봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 lambda = 0.01, cross-validation = 0.8422000000000001, n features abs > 0.01 = 4420\n",
      "L2 lambda = 0.1, cross-validation = 0.8550000000000001, n features abs > 0.01 = 4556\n",
      "L2 lambda = 1.0, cross-validation = 0.8638999999999999, n features abs > 0.01 = 4585\n",
      "L2 lambda = 10.0, cross-validation = 0.8517000000000001, n features abs > 0.01 = 4261\n",
      "L2 lambda = 100.0, cross-validation = 0.8221999999999999, n features abs > 0.01 = 2059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# for each cost\n",
    "for cost in [100, 10, 1, 0.1, 0.01]:\n",
    "\n",
    "    # build lasso regression\n",
    "    logistic_regression = LogisticRegression(\n",
    "        penalty='l2', C=cost)\n",
    "\n",
    "    # train cross validation\n",
    "    scores = cross_val_score(\n",
    "        logistic_regression, x, y, cv=n_cv)\n",
    "    average_score = sum(scores) / n_cv\n",
    "\n",
    "    # re-train using all data\n",
    "    logistic_regression.fit(x,y)\n",
    "\n",
    "    # number of used features\n",
    "    useful_features = list(\n",
    "        filter(lambda x:abs(x[1])>0.01,\n",
    "               enumerate(logistic_regression.coef_[0])\n",
    "              )\n",
    "    )\n",
    "\n",
    "    n_useful_features = len(useful_features)\n",
    "\n",
    "    print('L2 lambda = {}, cross-validation = {}, n features abs > 0.01 = {}'.format(1/cost, average_score, n_useful_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest 도 max depth 와 estimators 의 개수를 다르게 설정하여 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest max-depth = 2, n estimators = 100, cross-validation = 0.7665\n",
      "Random forest max-depth = 2, n estimators = 300, cross-validation = 0.8013999999999999\n",
      "Random forest max-depth = 2, n estimators = 500, cross-validation = 0.7855\n",
      "Random forest max-depth = 2, n estimators = 1000, cross-validation = 0.7975\n",
      "Random forest max-depth = 4, n estimators = 100, cross-validation = 0.7914\n",
      "Random forest max-depth = 4, n estimators = 300, cross-validation = 0.7988999999999999\n",
      "Random forest max-depth = 4, n estimators = 500, cross-validation = 0.8036000000000001\n",
      "Random forest max-depth = 4, n estimators = 1000, cross-validation = 0.8039999999999999\n",
      "Random forest max-depth = 6, n estimators = 100, cross-validation = 0.8029\n",
      "Random forest max-depth = 6, n estimators = 300, cross-validation = 0.8074999999999999\n",
      "Random forest max-depth = 6, n estimators = 500, cross-validation = 0.8129\n",
      "Random forest max-depth = 6, n estimators = 1000, cross-validation = 0.8120999999999998\n",
      "Random forest max-depth = 8, n estimators = 100, cross-validation = 0.8101999999999998\n",
      "Random forest max-depth = 8, n estimators = 300, cross-validation = 0.8154\n",
      "Random forest max-depth = 8, n estimators = 500, cross-validation = 0.8162\n",
      "Random forest max-depth = 8, n estimators = 1000, cross-validation = 0.8215\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for each max-depth\n",
    "for depth in [2, 4, 6, 8]:\n",
    "\n",
    "    # for each n estimators\n",
    "    for n_estimators in [100, 300, 500, 1000]:\n",
    "        random_forest = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=depth,\n",
    "        )\n",
    "\n",
    "        # train cross validation\n",
    "        scores = cross_val_score(\n",
    "            random_forest, x, y, cv=n_cv)\n",
    "        average_score = sum(scores) / n_cv\n",
    "\n",
    "        print('Random forest max-depth = {}, n estimators = {}, cross-validation = {}'.format(\n",
    "            depth, n_estimators, average_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting 도 max depth 와 n estimators 를 다르게 하여 cross validation 을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting tree max-depth = 2, n estimators = 100, cross-validation = 0.8184999999999999\n",
      "Gradient boosting tree max-depth = 2, n estimators = 300, cross-validation = 0.8192\n",
      "Gradient boosting tree max-depth = 2, n estimators = 500, cross-validation = 0.8219\n",
      "Gradient boosting tree max-depth = 2, n estimators = 1000, cross-validation = 0.8198000000000001\n",
      "Gradient boosting tree max-depth = 4, n estimators = 100, cross-validation = 0.8201\n",
      "Gradient boosting tree max-depth = 4, n estimators = 300, cross-validation = 0.8244999999999999\n",
      "Gradient boosting tree max-depth = 4, n estimators = 500, cross-validation = 0.8262\n",
      "Gradient boosting tree max-depth = 4, n estimators = 1000, cross-validation = 0.8259000000000001\n",
      "Gradient boosting tree max-depth = 6, n estimators = 100, cross-validation = 0.8289\n",
      "Gradient boosting tree max-depth = 6, n estimators = 300, cross-validation = 0.8164000000000001\n",
      "Gradient boosting tree max-depth = 6, n estimators = 500, cross-validation = 0.8199000000000002\n",
      "Gradient boosting tree max-depth = 6, n estimators = 1000, cross-validation = 0.8209\n",
      "Gradient boosting tree max-depth = 8, n estimators = 100, cross-validation = 0.8256000000000002\n",
      "Gradient boosting tree max-depth = 8, n estimators = 300, cross-validation = 0.8184000000000001\n",
      "Gradient boosting tree max-depth = 8, n estimators = 500, cross-validation = 0.8249000000000001\n",
      "Gradient boosting tree max-depth = 8, n estimators = 1000, cross-validation = 0.8219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# for each max-depth\n",
    "for depth in [2, 4, 6, 8]:\n",
    "\n",
    "    # for each n estimators\n",
    "    for n_estimators in [100, 300, 500, 1000]:\n",
    "        gbtree = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=depth,\n",
    "        )\n",
    "\n",
    "        # train cross validation\n",
    "        scores = cross_val_score(\n",
    "            random_forest, x, y, cv=n_cv)\n",
    "        average_score = sum(scores) / n_cv\n",
    "\n",
    "        print('Gradient boosting tree max-depth = {}, n estimators = {}, cross-validation = {}'.format(\n",
    "            depth, n_estimators, average_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost 는 scikit-learn 의 패키지가 아니기 때문에 직접 cross validation 과정을 구현하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost tree max-depth = 2, n estimators = 100, cross-validation = 0.7551\n",
      "XGBoost tree max-depth = 2, n estimators = 300, cross-validation = 0.7848\n",
      "XGBoost tree max-depth = 2, n estimators = 500, cross-validation = 0.7958\n",
      "XGBoost tree max-depth = 2, n estimators = 1000, cross-validation = 0.807\n",
      "XGBoost tree max-depth = 4, n estimators = 100, cross-validation = 0.7779\n",
      "XGBoost tree max-depth = 4, n estimators = 300, cross-validation = 0.8027999999999998\n",
      "XGBoost tree max-depth = 4, n estimators = 500, cross-validation = 0.8130000000000001\n",
      "XGBoost tree max-depth = 4, n estimators = 1000, cross-validation = 0.8166\n",
      "XGBoost tree max-depth = 6, n estimators = 100, cross-validation = 0.7888\n",
      "XGBoost tree max-depth = 6, n estimators = 300, cross-validation = 0.8087\n",
      "XGBoost tree max-depth = 6, n estimators = 500, cross-validation = 0.8150000000000001\n",
      "XGBoost tree max-depth = 6, n estimators = 1000, cross-validation = 0.8101999999999998\n",
      "XGBoost tree max-depth = 8, n estimators = 100, cross-validation = 0.7958000000000001\n",
      "XGBoost tree max-depth = 8, n estimators = 300, cross-validation = 0.8103\n",
      "XGBoost tree max-depth = 8, n estimators = 500, cross-validation = 0.8088000000000001\n",
      "XGBoost tree max-depth = 8, n estimators = 1000, cross-validation = 0.807\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "y_xgb = np.zeros(y.shape[0])\n",
    "y_xgb[np.where(y == 1)[0]] = 1\n",
    "\n",
    "# for each max-depth\n",
    "for depth in [2, 4, 6, 8]:\n",
    "\n",
    "    # for each n estimators\n",
    "    for n_estimators in [100, 300, 500, 1000]:\n",
    "\n",
    "        # cross - validation (manually)\n",
    "        validation_scores = []\n",
    "\n",
    "        for b in range(10):\n",
    "            test_idx = [i for i in range(b*1000, (b+1)*1000)]\n",
    "            train_idx = [i for i in range(10000) if not i in test_idx]\n",
    "            train_idx = np.asarray(train_idx)\n",
    "            test_idx = np.asarray(test_idx)\n",
    "\n",
    "            dtrain = xgb.DMatrix(data=x[train_idx], label=y_xgb[train_idx])\n",
    "            dtest = xgb.DMatrix(data=x[test_idx])\n",
    "\n",
    "            param = {'max_depth': depth, 'eta': 0.3, 'silent': 0, 'objective': 'binary:logistic'}\n",
    "            param['nthread'] = 4\n",
    "            param['eval_metric'] = 'auc'\n",
    "            bst = xgb.train(param, dtrain, n_estimators)\n",
    "\n",
    "            pred_score = bst.predict(dtest)\n",
    "            y_pred = np.zeros(pred_score.shape[0])\n",
    "            y_pred[np.where(pred_score > 0.5)[0]] = 1\n",
    "            n_correct = np.where(y_pred == y_xgb[test_idx])[0].shape[0]\n",
    "            accuracy = n_correct / y_pred.shape[0]\n",
    "            validation_scores.append(accuracy)\n",
    "\n",
    "        average_score = sum(validation_scores) / len(validation_scores)\n",
    "\n",
    "        print('XGBoost tree max-depth = {}, n estimators = {}, cross-validation = {}'.format(\n",
    "            depth, n_estimators, average_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Projection\n",
    "\n",
    "Scikit-learn 의 LSHForest 는 한 종류의 metric 만 이용 가능하며, LSH 의 문제점들을 개선하는 방향으로 추가적인 개발이 되지 않았습니다. Scikit-learn 의 0.21 이후부터는 LSHForest 는 더 이상 제공되지 않는다고 합니다. 또한 Scikit-learn 의 다른 인덱서인 BallTree 와 KDTree 는 sparse matrix 에 대한 인덱싱을 지원하지 않습니다.\n",
    "\n",
    "안정적인 성능을 내기 위해서는 많은 작업들이 필요하지만, 기본적인 LSH 의 코드는 손쉽게 만들 수 있습니다. 이 튜토리얼을 통하여 Random Projection 을 이용하는 LSH 를 직접 개발해 봅니다.\n",
    "\n",
    "Hash function 의 설계에 따라 다양하게 인덱서를 변형할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soynlp=0.0.492\n",
      "added lovit_textmining_dataset\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from navernews_10days import get_bow\n",
    "\n",
    "X, idx_to_vocab, vocab_to_idx = get_bow(date='2016-10-20', tokenize='noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30091, 9774)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.random.random_samples 는 [0, 1) 사이의 값을 생성하기 때문에 0.5 를 뺍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9774, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_mapper(input_dim, output_dim, b_scale=0.1):\n",
    "    # uniform distribution\n",
    "    M = np.random.random_sample((input_dim, output_dim)) - 0.5\n",
    "    M = normalize(M, axis=0, norm='l2')\n",
    "    b = (np.random.random_sample(1) - 0.5) * b_scale\n",
    "    return M, b\n",
    "\n",
    "n_codes = 10\n",
    "M, b = generate_mapper(X.shape[1], n_codes)\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00052057])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse matrix 와 numpy.ndarray 의 곱은 safe_sparse_dot 함수를 이용해야 효율적입니다. safe_sparse_dot 함수는 sparse matrix 의 nonzero element 기준으로 곱셈을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30091, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "\n",
    "def transform(X, mapper, dense_output=False):\n",
    "    Y = safe_sparse_dot(X, mapper, dense_output)\n",
    "    return Y\n",
    "\n",
    "Y = transform(X, M)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.ndarray 형식의 float vector 는 dtype 을 변경하여 손쉽게 integer vector 로 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.23522713, -2.31475906, -2.45704571,  3.02593109,  0.01352958,\n",
       "       -1.19656845, -1.11870652, -0.61412234,  2.40003218,  0.74038135])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[1] / 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -2, -2,  3,  0, -1, -1,  0,  2,  0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(Y[1] / 0.01, dtype=np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign 함수를 이용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  1,  0, -1, -1,  0,  1,  0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(np.asarray(Y[1] / 0.01, dtype=np.int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality Sensitive Hashing\n",
    "\n",
    "앞서 만든 transform 함수를 이용하여 hash function 인 encode 함수를 만듭니다. Python 의 list 는 hashing 이 되지 않기 때문에 key 의 데이터 타입을 tuple 로 변경합니다. 모든 데이터에 대한 hash code 를 만든 뒤, 이를 기준으로 dict 에 row index 를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def encode(X, mapper, b, radius=1):\n",
    "    b_ = b / radius\n",
    "    # Y = (transform(X, mapper) - b) / radius\n",
    "    Y = np.sign((transform(X, mapper) - b))\n",
    "    C = np.asarray(Y, dtype=np.int)\n",
    "    # numpy.ndarray to tuple\n",
    "    C = [tuple(c) for c in C.tolist()]\n",
    "    return C\n",
    "\n",
    "def indexing(C, bucket=None):\n",
    "    if bucket is None:\n",
    "        bucket = defaultdict(lambda: [])\n",
    "    elif isinstance(bucket, dict):\n",
    "        bucket = defaultdict(lambda: [], bucket)\n",
    "\n",
    "    for i, c in enumerate(C):\n",
    "        bucket[c].append(i)\n",
    "    return dict(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 0.1\n",
    "\n",
    "C = encode(X, M, b, radius)\n",
    "buckets = indexing(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단 한번이 random projection 으로는 buckets 의 사이즈가 불균형적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, -1, -1, -1, 1, 1, -1, -1, -1, 1) has 116 items\n",
      "(1, -1, 1, -1, 1, -1, 1, -1, 1, 1) has 155 items\n",
      "(-1, -1, -1, 1, 1, 1, 1, 1, 1, -1) has 127 items\n",
      "(-1, 1, -1, -1, 1, -1, 1, -1, 1, 1) has 810 items\n",
      "(-1, -1, -1, 1, 1, 1, 1, 1, 1, 1) has 120 items\n",
      "(1, 1, -1, 1, -1, 1, 1, -1, -1, 1) has 120 items\n",
      "(1, -1, -1, -1, 1, 1, 1, -1, -1, 1) has 189 items\n",
      "(1, 1, -1, 1, 1, 1, 1, -1, -1, 1) has 186 items\n",
      "(1, -1, -1, 1, 1, 1, 1, -1, -1, 1) has 123 items\n",
      "(1, 1, -1, -1, -1, 1, 1, -1, -1, 1) has 155 items\n",
      "(-1, 1, -1, -1, 1, -1, -1, -1, 1, 1) has 998 items\n",
      "(1, 1, 1, -1, -1, 1, 1, -1, -1, 1) has 136 items\n",
      "(-1, -1, 1, 1, -1, 1, 1, -1, -1, 1) has 173 items\n",
      "(1, 1, -1, -1, 1, 1, 1, -1, -1, 1) has 122 items\n",
      "(1, -1, -1, -1, -1, 1, -1, -1, -1, 1) has 108 items\n",
      "(-1, -1, 1, 1, 1, 1, 1, -1, -1, 1) has 184 items\n",
      "(-1, 1, 1, -1, -1, 1, 1, -1, -1, 1) has 119 items\n"
     ]
    }
   ],
   "source": [
    "for code, bucket in buckets.items():\n",
    "    if len(bucket) < 100:\n",
    "        continue\n",
    "    print('{} has {} items'.format(code, len(bucket)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검색된 뉴스를 확인하기 위하여 뉴스를 list 로 읽어둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navernews_10days import get_news_paths\n",
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "\n",
    "path = get_news_paths(date='2016-10-20')\n",
    "docs = list(DoublespaceLineCorpus(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인덱싱 과정은 앞서 구현한 함수를 이용하며, 검색 함수만 따로 구현하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "class HashingBasedIndexer:\n",
    "    def __init__(self, n_codes=10, n_layers=10, radius=1, b_scale=0.05):\n",
    "        self.n_codes = n_codes\n",
    "        self.n_layers = n_layers\n",
    "        self.radius = radius\n",
    "        self.b_scale = b_scale\n",
    "\n",
    "    def train(self, X):\n",
    "        input_dim = X.shape[1]\n",
    "        self.X = X\n",
    "        self._generate_mapper(input_dim, self.n_layers)\n",
    "        self._indexing(X, self.mappers, self.biases)\n",
    "\n",
    "    def _generate_mapper(self, input_dim, n_layers):\n",
    "        # initialize\n",
    "        self.biases = []\n",
    "        self.buckets = []\n",
    "        self.mappers = []\n",
    "\n",
    "        # generate mapper\n",
    "        for _ in range(n_layers):\n",
    "            M, b = generate_mapper(input_dim, n_codes)\n",
    "            self.mappers.append(M)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    def _indexing(self, X, mappers, biases):\n",
    "        for M, b in zip(mappers, biases):\n",
    "            C = encode(X, M, b, self.radius)\n",
    "            self.buckets.append(indexing(C))\n",
    "\n",
    "    def find_similar(self, query_vec, topk=10, candidates_factor=1.0, debug=False):\n",
    "        candidates = self._get_candidates(query_vec, topk, candidates_factor)\n",
    "        if debug:\n",
    "            print('num candidatse = {}'.format(candidates.shape[0]))\n",
    "        dist, idxs = self._compute_distance(query_vec, candidates, topk)\n",
    "        return dist, idxs\n",
    "\n",
    "    def _get_candidates(self, query_vec, min_num, candidates_factor):\n",
    "        # {idx:co-occurrence}\n",
    "        cooccurrences = defaultdict(int)\n",
    "        for M, b, bucket in zip(self.mappers, self.biases, self.buckets):\n",
    "            C = encode(query_vec, M, b, self.radius)[0]\n",
    "            for idx in bucket.get(C, []):\n",
    "                cooccurrences[idx] += 1\n",
    "\n",
    "        # {co-occurrence:[idx, ...]}\n",
    "        group_by = defaultdict(lambda: [])\n",
    "        for idx, count in cooccurrences.items():\n",
    "            group_by[count].append(idx)\n",
    "\n",
    "        n_max_candidates = int(candidates_factor * min_num)\n",
    "        candidates = []\n",
    "        for count in sorted(group_by, key=lambda x:-x):\n",
    "            if len(candidates) >= n_max_candidates:\n",
    "                break\n",
    "            candidates += group_by[count]\n",
    "\n",
    "        # as numpy.ndarray\n",
    "        return np.asarray(candidates, dtype=np.int)\n",
    "\n",
    "    def _compute_distance(self, query_vec, candidates, topk):\n",
    "        dist = pairwise_distances(self.X[candidates], query_vec, metric='cosine').reshape(-1)        \n",
    "        sim_ref_idxs = dist.argsort()[:topk]\n",
    "        sim_idxs = candidates[sim_ref_idxs]\n",
    "        sim_dist = dist[sim_ref_idxs]\n",
    "        return sim_dist, sim_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구현한 함수를 테스트해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.63 s, sys: 28 ms, total: 3.66 s\n",
      "Wall time: 648 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "indexer = HashingBasedIndexer(n_codes=6, n_layers=8, radius=0.3)\n",
    "indexer.train(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bucket 만 잘 나뉘어진다면 실제 거리 계산을 수행하는 횟수가 크게 줄어듭니다. 그리고 그 성능은 hash function 의 설계에 전적으로 달려있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query = 15\n",
    "query_vec = X[query].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num candidatse = 272\n",
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 5.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dist, idxs = indexer.find_similar(query_vec, candidates_factor=5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[idx = 15, cos = 1.0] 클린턴 득표율 50 목표 가능성 아주 크다  워싱턴 연합뉴스 강영두 특파원 미국 민주당 대선후보 힐러리 클린턴이 다음달 8일 대선에서 400명 이상의 선거인단을 확보하면서 대승을 거둘 수 있다는 분석이 나왔다  미국 민주당 대선후보 힐러리 클린턴이 지난 10일 현지시간 오하이오 주 콜럼버스에서 유세하는 모습 연합뉴스  미 공화당 전략가인 스티브 슈미트는 1 ...\n",
      "\n",
      "[idx = 15006, cos = 0.846] 미국 민주당 대선후보 힐러리 클린턴이 다음달 8일 대선에서 400명 이상의 선거인단을 확보하면서 대승을 거둘 수 있다는 분석이 나왔다  미 공화당 전략가인 스티브 슈미트는 현지시간 19일 방송의 모닝조 프로그램 인터뷰에서 이 같이 전망했다 슈미트는 2008년 존 매케인의 대선캠프에 관여했다 간접선거인 미 대선에서 승리에 필요한 선거인단 매직 넘버 는 전체  ...\n",
      "\n",
      "[idx = 11309, cos = 0.698] 공화 상 하원선거도 고전할 듯 2016년 미국 대선이 19일 앞으로 다가온 가운데 민주당 후보 힐러리 클린턴 전 국무장관이 400명 이상의 선거인단을 확보해 압승을 거둘 것이라는 전망이 제기됐다 미 공화당 전략가인 스티브 슈밋은 19일 방송의 모닝조 프로그램에 출연 클린턴이 당선 매직넘버인 선거인단 270명을 훌쩍 넘어선 400명을 확보해 공화당 도널드 트 ...\n",
      "\n",
      "[idx = 17330, cos = 0.484] 워싱턴 노컷뉴스 임미현 특파원 미국 공화당 대선 후보 도널드 트럼프가 대선 결과에 불복할 수 있음을 시사해 파장이 일고 있다  트럼프는 19일 현지시간 네바다주 라스베이거스 네바다 대학에서 열린 3차 토론에서 대선에서 패배할 경우 결과에 승복하겠느냐는 사회자 크리스 윌리스의 질문에 그때 가서 말하겠다 고 답했다  트럼프는 대선 결과를 받아들이는 미국의 전통 ...\n",
      "\n",
      "[idx = 1281, cos = 0.468] 1차 2차 3차로 갈수록 격차 좁혀져 3차 토론 가장 근소한 차  마지막 토론도 힐러리 승 52 대 39 라스베이거스 연합뉴스 19일 현지시간 미국 라스베이거스 네바다대학에서 열린 대선후보 3차 토론에서 민주당 대선후보 힐러리 클린턴이 공화당 대선후보 도널드 트럼프를 이긴 것으로 나타났다 방송은 토론 직후 시청자를 대상으로 여론조사를 실시한 결과 52 가  ...\n",
      "\n",
      "[idx = 9774, cos = 0.467] 헤럴드경제 문재연 기자 로비업체 그룹의 회장인 에드 로저스는 워싱턴포스트 와 포스트파티션 블로그 에 19일 현지시간 치러진 3차 대선 토론의 승자를 공화당 대선후보 도널드 트럼프로 꼽았다 하지만 오는 11월 8일 대선의 판세를 가를 만큼 트럼프가 선전하지는 못했다며 클린턴의 우승 가능성을 시사했다  지난 토론과 비교해 민주당 대선후보 힐러리 클린턴의 발언에 ...\n",
      "\n",
      "[idx = 29096, cos = 0.463] 미국 대선 마지막 승부처 굳히기 뒤집기  앵커  오늘 20일 오전 10시부터 90분간 미국 대선후보간 3차 토론이 열립니다  민주당 힐러리 클린턴이 승기를 굳힐지 공화당 도널드 트럼프가 뒤집기 성공할지 마지막 승부처라고 할 수 있습니다  워싱턴에서 김범현 특파원입니다  기자  미국 라스베이거스에 위치한 네바다대학은 민주당 힐러리 클린턴 공화당 도널드 트럼프 ...\n",
      "\n",
      "[idx = 9434, cos = 0.461] 헤럴드경제 문재연 기자 또 한번의 추잡한 설전만 오고갈 것인가 아니면 미국의 미래 를 논하는 공론장이 형성될 것인가 미국 대선 마지막 3차 토론이 19일 현지시간 오후 9시 동부시간 기준 네바다 주 라스베이가스 네바다 대학에서 열릴 예정이다 이날 토론에서는 이민과 복지 경제 외교 대통령의 자질 그리고 대법원 인사 등 미국 정책의 방향을 결정할 주요 의제가  ...\n",
      "\n",
      "[idx = 15632, cos = 0.459] 미대선 3차 토론 승자 힐러리 클린턴 우승 굳히기 들어가  미대선 3차 토론 사진 연합뉴스  19일 현지시간 미국 네바다 주 라스베이거스 네바다대학에서 끝난 미국 대통령 선거 3차 토론의 승자는 민주당의 후보 힐러리 클린턴 전 국무장관으로 나타났습니다  미국 방송이 토론 직후 와 공동으로 토론 시청자를 대상으로 벌인 여론조사에서 응답자의 52 가 클린턴을  ...\n",
      "\n",
      "[idx = 17339, cos = 0.458] 3차 토론 뒤 여론조사 누가 더 진실한 후보 질문엔 트럼프가 앞서기도  노컷뉴스 김중호 기자 트럼프 미 공화당 대선후보 와 클린턴 미 민주당 대선후보 사진 유튜브 화면 캡처 3차 토론 뒤 여론조사에서도 힐러리 클린턴이 승리했다는 답변이 많았지만 그 격차는 더욱 좁혀졌다  19일 현지시간 미국 네바다 주 라스베이거스 네바다대학에서 끝난 미국 대통령 선거 3차 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d, idx in zip(dist, idxs):\n",
    "    print('[idx = {}, cos = {:.3}] {} ...\\n'.format(idx, 1 - d, docs[idx][:200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various Hash Function (NMF based Hash Function)\n",
    "\n",
    "NMF 로 학습한 components 를 mapper 로 이용할 수도 있습니다. Sign 함수와 함께 이용하면 각 component 에 해당하는 토픽과 비슷하면 1 의 hash code value 를 가지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator NMF from version 0.20.0 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 9774)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../day4_topicmodeling/2016-10-20-nmf.pkl', 'rb') as f:\n",
    "    nmf_model = pickle.load(f)\n",
    "components = nmf_model.components_\n",
    "components.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation 을 이용하여 components 를 sampling 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 9 8 6 1 5 3 0 7]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.permutation(10))\n",
    "\n",
    "def sample_index(high, n_samples):\n",
    "    return np.random.permutation(high)[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapper 와 bias 를 따로 만든 뒤, 다시 한 번 인덱싱을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = normalize(components, norm='l2')\n",
    "n_layers = 16\n",
    "n_codes = 5\n",
    "n_components = components.shape[0]\n",
    "\n",
    "custom_mapper = [\n",
    "    components[sample_index(n_components, n_codes)].transpose() \n",
    "    for _ in range(n_layers)\n",
    "]\n",
    "\n",
    "custom_bias = [\n",
    "    np.random.random_sample(1) * 0.05\n",
    "    for _ in range(n_layers)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer.radius = 0.5\n",
    "indexer._indexing(X, custom_mapper, custom_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF 로 만든 인덱서도 테스트해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num candidatse = 272\n",
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 3.72 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dist, idxs = indexer.find_similar(query_vec, candidates_factor=2, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[idx = 15, cos = 1.0] 클린턴 득표율 50 목표 가능성 아주 크다  워싱턴 연합뉴스 강영두 특파원 미국 민주당 대선후보 힐러리 클린턴이 다음달 8일 대선에서 400명 이상의 선거인단을 확보하면서 대승을 거둘 수 있다는 분석이 나왔다  미국 민주당 대선후보 힐러리 클린턴이 지난 10일 현지시간 오하이오 주 콜럼버스에서 유세하는 모습 연합뉴스  미 공화당 전략가인 스티브 슈미트는 1 ...\n",
      "\n",
      "[idx = 15006, cos = 0.846] 미국 민주당 대선후보 힐러리 클린턴이 다음달 8일 대선에서 400명 이상의 선거인단을 확보하면서 대승을 거둘 수 있다는 분석이 나왔다  미 공화당 전략가인 스티브 슈미트는 현지시간 19일 방송의 모닝조 프로그램 인터뷰에서 이 같이 전망했다 슈미트는 2008년 존 매케인의 대선캠프에 관여했다 간접선거인 미 대선에서 승리에 필요한 선거인단 매직 넘버 는 전체  ...\n",
      "\n",
      "[idx = 11309, cos = 0.698] 공화 상 하원선거도 고전할 듯 2016년 미국 대선이 19일 앞으로 다가온 가운데 민주당 후보 힐러리 클린턴 전 국무장관이 400명 이상의 선거인단을 확보해 압승을 거둘 것이라는 전망이 제기됐다 미 공화당 전략가인 스티브 슈밋은 19일 방송의 모닝조 프로그램에 출연 클린턴이 당선 매직넘버인 선거인단 270명을 훌쩍 넘어선 400명을 확보해 공화당 도널드 트 ...\n",
      "\n",
      "[idx = 17330, cos = 0.484] 워싱턴 노컷뉴스 임미현 특파원 미국 공화당 대선 후보 도널드 트럼프가 대선 결과에 불복할 수 있음을 시사해 파장이 일고 있다  트럼프는 19일 현지시간 네바다주 라스베이거스 네바다 대학에서 열린 3차 토론에서 대선에서 패배할 경우 결과에 승복하겠느냐는 사회자 크리스 윌리스의 질문에 그때 가서 말하겠다 고 답했다  트럼프는 대선 결과를 받아들이는 미국의 전통 ...\n",
      "\n",
      "[idx = 1281, cos = 0.468] 1차 2차 3차로 갈수록 격차 좁혀져 3차 토론 가장 근소한 차  마지막 토론도 힐러리 승 52 대 39 라스베이거스 연합뉴스 19일 현지시간 미국 라스베이거스 네바다대학에서 열린 대선후보 3차 토론에서 민주당 대선후보 힐러리 클린턴이 공화당 대선후보 도널드 트럼프를 이긴 것으로 나타났다 방송은 토론 직후 시청자를 대상으로 여론조사를 실시한 결과 52 가  ...\n",
      "\n",
      "[idx = 9774, cos = 0.467] 헤럴드경제 문재연 기자 로비업체 그룹의 회장인 에드 로저스는 워싱턴포스트 와 포스트파티션 블로그 에 19일 현지시간 치러진 3차 대선 토론의 승자를 공화당 대선후보 도널드 트럼프로 꼽았다 하지만 오는 11월 8일 대선의 판세를 가를 만큼 트럼프가 선전하지는 못했다며 클린턴의 우승 가능성을 시사했다  지난 토론과 비교해 민주당 대선후보 힐러리 클린턴의 발언에 ...\n",
      "\n",
      "[idx = 29096, cos = 0.463] 미국 대선 마지막 승부처 굳히기 뒤집기  앵커  오늘 20일 오전 10시부터 90분간 미국 대선후보간 3차 토론이 열립니다  민주당 힐러리 클린턴이 승기를 굳힐지 공화당 도널드 트럼프가 뒤집기 성공할지 마지막 승부처라고 할 수 있습니다  워싱턴에서 김범현 특파원입니다  기자  미국 라스베이거스에 위치한 네바다대학은 민주당 힐러리 클린턴 공화당 도널드 트럼프 ...\n",
      "\n",
      "[idx = 9434, cos = 0.461] 헤럴드경제 문재연 기자 또 한번의 추잡한 설전만 오고갈 것인가 아니면 미국의 미래 를 논하는 공론장이 형성될 것인가 미국 대선 마지막 3차 토론이 19일 현지시간 오후 9시 동부시간 기준 네바다 주 라스베이가스 네바다 대학에서 열릴 예정이다 이날 토론에서는 이민과 복지 경제 외교 대통령의 자질 그리고 대법원 인사 등 미국 정책의 방향을 결정할 주요 의제가  ...\n",
      "\n",
      "[idx = 15632, cos = 0.459] 미대선 3차 토론 승자 힐러리 클린턴 우승 굳히기 들어가  미대선 3차 토론 사진 연합뉴스  19일 현지시간 미국 네바다 주 라스베이거스 네바다대학에서 끝난 미국 대통령 선거 3차 토론의 승자는 민주당의 후보 힐러리 클린턴 전 국무장관으로 나타났습니다  미국 방송이 토론 직후 와 공동으로 토론 시청자를 대상으로 벌인 여론조사에서 응답자의 52 가 클린턴을  ...\n",
      "\n",
      "[idx = 17339, cos = 0.458] 3차 토론 뒤 여론조사 누가 더 진실한 후보 질문엔 트럼프가 앞서기도  노컷뉴스 김중호 기자 트럼프 미 공화당 대선후보 와 클린턴 미 민주당 대선후보 사진 유튜브 화면 캡처 3차 토론 뒤 여론조사에서도 힐러리 클린턴이 승리했다는 답변이 많았지만 그 격차는 더욱 좁혀졌다  19일 현지시간 미국 네바다 주 라스베이거스 네바다대학에서 끝난 미국 대통령 선거 3차 ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d, idx in zip(dist, idxs):\n",
    "    print('[idx = {}, cos = {:.3}] {} ...\\n'.format(idx, 1 - d, docs[idx][:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
